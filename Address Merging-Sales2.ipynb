{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scourgify import normalize_address_record\n",
    "import usaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['address_number','street_name','street_type','unit_number'']\n",
    "#['address_number','street_name','street_type','unit_number']\n",
    "\n",
    "def tag_street(address):\n",
    "    try:\n",
    "        out = usaddress.tag(address, tag_mapping={\n",
    "       'Recipient': 'unit_number',\n",
    "       'AddressNumber': 'address_number',\n",
    "       'AddressNumberPrefix': 'address_number',\n",
    "       'AddressNumberSuffix': 'address_number',\n",
    "       'StreetName': 'street_name',\n",
    "       'StreetNamePreDirectional': 'street_name',\n",
    "       'StreetNamePreModifier': 'street_name',\n",
    "       'StreetNamePreType': 'street_name',\n",
    "       'StreetNamePostDirectional': 'street_name',\n",
    "       'StreetNamePostModifier': 'street_name',\n",
    "       'SecondStreetName': 'street_name',\n",
    "       'StreetNamePostType': 'street_type',\n",
    "       'SecondStreetNamePostType': 'street_type',\n",
    "       'CornerOf': 'street_name',\n",
    "       'IntersectionSeparator': 'street_name',\n",
    "       'LandmarkName': 'street_name',\n",
    "       'USPSBoxGroupID': 'street_name',\n",
    "       'USPSBoxGroupType': 'street_name',\n",
    "       'USPSBoxID': 'street_name',\n",
    "       'USPSBoxType': 'street_name',\n",
    "       'BuildingName': 'unit_number',\n",
    "       'OccupancyType': 'unit_number',\n",
    "       'OccupancyIdentifier': 'unit_number',\n",
    "       'SubaddressIdentifier': 'unit_number',\n",
    "       'SubaddressType': 'unit_number',\n",
    "       'PlaceName': 'city',\n",
    "       'StateName': 'state',\n",
    "       'ZipCode': 'postal_code'\n",
    "        })\n",
    "        return dict(out[0])\n",
    "    except Exception as e_tag:\n",
    "        return {'e_tag': e_tag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch_norm_tag(full_address, func=normalize_address_record):\n",
    "    try:\n",
    "        out = func(full_address)\n",
    "        out.update(tag_street(out['address_line_1']))\n",
    "        return out\n",
    "    \n",
    "    except Exception as e_norm:\n",
    "        out = tag_street(full_address)\n",
    "        e_dict = {'e_norm': e_norm}\n",
    "        out.update(e_dict)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with D+\\sd+, d+\\sD+, D+\\s&\\sD+ unit numbers\n",
    "# Deal with \"Buena Vista Avenue\" which get confused:\n",
    "    \n",
    "def unit_extract(addy_series):\n",
    "    \n",
    "    df = pd.DataFrame(index=addy_series.index)\n",
    "\n",
    "    # Split the last element of 'address' on the right - \"suffix\"\n",
    "    df[['street_name','suffix']] = addy_series.str.strip().str.upper().str.rsplit(n=1, expand=True)\n",
    "\n",
    "    ## Drop leading spaces & special characters in 'suffix'\n",
    "    df['street_name'] = df['street_name'].str.strip()\n",
    "    df['suffix'] = df['suffix'].str.strip()\n",
    "\n",
    "    ## Find 'unit' numbers, such as: 1, 123, 12345D, 15CD, A, A1, A123:\n",
    "    pat = '(\\d+\\D*|^[\\D]\\d+$|^[ABCD]$|^AB$|^CD$|^EF$|^FE$)'\n",
    "    df['unit'] = df['suffix'].str.extract(pat)\n",
    "\n",
    "    ## Streets such as 23rd, 1st, 102nd also match 'pat', remove them:\n",
    "    df['unit']=df['unit'].str.replace('(\\d*[RSTN][DTHD])','')\n",
    "\n",
    "    ## Whatever is NOT unit should be added back to addess:\n",
    "    m = df['unit'].isna()\n",
    "    df.loc[m,'street_name'] = df.loc[m,'street_name'] + ' ' + df.loc[m,'suffix']\n",
    "    df.loc[~m,'street_name'] = df.loc[~m,'street_name'] + ', UNIT ' + df.loc[~m,'suffix']\n",
    "\n",
    "    #df.drop('suffix', axis=1, inplace=True)\n",
    "    \n",
    "    return df['street_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use fuzzywuzzy to match zip codes:\n",
    "\n",
    "def fuzzy_correct(check_value, correct_set, thresh=80, fscorer=fuzz.WRatio, imp='#####'):\n",
    "    \n",
    "    # From great tuttorial here: https://michelleful.github.io/\n",
    "    \n",
    "    if check_value in correct_set:  # might want to make this a dict for O(1) lookups\n",
    "        return check_value, 100\n",
    "\n",
    "    new_value, score = process.extractOne(check_value, correct_set, scorer=fscorer)\n",
    "    if score < thresh:\n",
    "        return imp, score\n",
    "    else:\n",
    "        return new_value, score\n",
    "    \n",
    "def fuzzy_series(check_series, correct_areas, thresh=90, fscorer=fuzz.WRatio):\n",
    "    \n",
    "    # Series holders for return:\n",
    "    check_new_areas = check_series.copy()\n",
    "    check_count_areas = check_new_areas.copy()\n",
    "    \n",
    "    # List of unique values to check:\n",
    "    check_areas = list(check_new_areas.unique())    \n",
    "\n",
    "    # Dictionaries for mapping:\n",
    "    count_dict = {}\n",
    "    area_dict = {}\n",
    "\n",
    "    # Build dictionaries for mapping with FuzzyWuzzy:\n",
    "    for area in tqdm(check_areas):\n",
    "        correct_area , count = fuzzy_correct(area, correct_areas, thresh, fscorer)\n",
    "        count_dict[area] = count\n",
    "        area_dict[area] = correct_area\n",
    "    \n",
    "    # Map dictionaries\n",
    "    check_new_areas = check_new_areas.map(area_dict, na_action='ignore')\n",
    "    check_count_areas = check_count_areas.map(count_dict, na_action='ignore')\n",
    "\n",
    "    return check_new_areas, check_count_areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Canonical addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 211956 entries, 0 to 212553\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   address                211956 non-null  object \n",
      " 1   address_number         211956 non-null  object \n",
      " 2   address_number_suffix  3700 non-null    object \n",
      " 3   street_name            211956 non-null  object \n",
      " 4   street_type            209573 non-null  object \n",
      " 5   zip                    211956 non-null  object \n",
      " 6   long                   211956 non-null  float64\n",
      " 7   lat                    211956 non-null  float64\n",
      "dtypes: float64(2), object(6)\n",
      "memory usage: 14.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Column sthat we need for deduping:\n",
    "addy_columns = ['Address', 'Address Number', 'Address Number Suffix', 'Street Name', 'Street Type', \n",
    "           'Zipcode', 'Longitude', 'Latitude']\n",
    "column_names = ['address', 'address_number', 'address_number_suffix', 'street_name', 'street_type', \n",
    "           'zip', 'long', 'lat']\n",
    "\n",
    "# Import Assessor's data:\n",
    "addy_path = r'C:\\SFSU\\Spring 2020\\Project\\Data\\sf-addresses-enterprise-addressing-system\\addresses-enterprise-addressing-system.csv' # use your path\n",
    "addy_frame = pd.read_csv(addy_path, header=0, index_col=False, \n",
    "                        dtype={'Zipcode':str, 'Address Number':str},\n",
    "                        usecols= addy_columns).drop_duplicates()\n",
    "addy_frame.columns = column_names\n",
    "addy_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "addy_frame['street_name'] = addy_frame.street_name.str.lstrip('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>address_number</th>\n",
       "      <th>address_number_suffix</th>\n",
       "      <th>street_name</th>\n",
       "      <th>street_type</th>\n",
       "      <th>zip</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2433A 23RD AVE</td>\n",
       "      <td>2433</td>\n",
       "      <td>A</td>\n",
       "      <td>23RD</td>\n",
       "      <td>AVE</td>\n",
       "      <td>94116</td>\n",
       "      <td>-122.480264</td>\n",
       "      <td>37.742226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312A UNION ST</td>\n",
       "      <td>312</td>\n",
       "      <td>A</td>\n",
       "      <td>UNION</td>\n",
       "      <td>ST</td>\n",
       "      <td>94133</td>\n",
       "      <td>-122.404777</td>\n",
       "      <td>37.801114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>369A DUNCAN ST</td>\n",
       "      <td>369</td>\n",
       "      <td>A</td>\n",
       "      <td>DUNCAN</td>\n",
       "      <td>ST</td>\n",
       "      <td>94131</td>\n",
       "      <td>-122.428290</td>\n",
       "      <td>37.745765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1726A CABRILLO ST</td>\n",
       "      <td>1726</td>\n",
       "      <td>A</td>\n",
       "      <td>CABRILLO</td>\n",
       "      <td>ST</td>\n",
       "      <td>94121</td>\n",
       "      <td>-122.477383</td>\n",
       "      <td>37.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>3233A 16TH ST</td>\n",
       "      <td>3233</td>\n",
       "      <td>A</td>\n",
       "      <td>16TH</td>\n",
       "      <td>ST</td>\n",
       "      <td>94110</td>\n",
       "      <td>-122.424803</td>\n",
       "      <td>37.764482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              address address_number address_number_suffix street_name  \\\n",
       "1      2433A 23RD AVE           2433                     A        23RD   \n",
       "2       312A UNION ST            312                     A       UNION   \n",
       "37     369A DUNCAN ST            369                     A      DUNCAN   \n",
       "69  1726A CABRILLO ST           1726                     A    CABRILLO   \n",
       "74      3233A 16TH ST           3233                     A        16TH   \n",
       "\n",
       "   street_type    zip        long        lat  \n",
       "1          AVE  94116 -122.480264  37.742226  \n",
       "2           ST  94133 -122.404777  37.801114  \n",
       "37          ST  94131 -122.428290  37.745765  \n",
       "69          ST  94121 -122.477383  37.775000  \n",
       "74          ST  94110 -122.424803  37.764482  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = ~addy_frame.address_number_suffix.isna()\n",
    "addy_frame[m].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 112970 entries, 0 to 112969\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   address  112970 non-null  object\n",
      " 1   zip      112970 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Columns that we need for deduping:\n",
    "sales_cols = ['Address','Zip Code']\n",
    "\n",
    "# Import sales data:\n",
    "sales_path = r'C:\\SFSU\\Spring 2020\\Project\\Data\\salesframe.csv' # use your path\n",
    "sales_frame = pd.read_csv(sales_path, header=0, index_col=False, usecols=sales_cols, \n",
    "                         dtype={'Zip Code':str})\n",
    "sales_frame.columns = ['address', 'zip']\n",
    "\n",
    "# Drop records without address & replace nan zips\n",
    "sales_frame['zip'].fillna('99999', inplace=True)\n",
    "sales_frame.drop(sales_frame[sales_frame['address'].isna()].index, inplace=True)\n",
    "\n",
    "sales_frame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Sales frame preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Address convenient columns:\n",
    "sales_frame[['no1','street_name']] = sales_frame['address'].copy().str.split(n=1, expand=True)\n",
    "sales_frame[['street_name','street_type']] = sales_frame['street_name'].copy().str.rsplit(n=1, expand=True)\n",
    "\n",
    "# Process columns:\n",
    "sales_frame['unit_number'] = sales_frame['street_type'].str.replace(r\"[a-zA-Z]\",'')\n",
    "sales_frame['street_type'] = sales_frame['street_type'].str.replace(r\"[0-9]\",'')\n",
    "\n",
    "# Build comparison column:\n",
    "sales_frame['street_suffix'] = (sales_frame['street_name'].fillna('')\n",
    "                                 +' ' + sales_frame['street_type'].fillna('')).str.lower()\n",
    "\n",
    "sales_frame['address_number'] = sales_frame.no1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Full address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_frame['full_address'] = sales_frame.address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pipeline\n",
    "\n",
    "Although, addresses at the head of dataset look clean, there are in fact misformatted addresses. Such as addresses where street_name includes unit_number which will prevent us from mathcing the addresses as units also come in a vaiety of forms such as UNIT123, # 123, APP123, etc\n",
    "\n",
    "### 3.1. Extract Unit numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'Unit' as parsers confuse them with street numbers:\n",
    "sales_frame['full_address'] = unit_extract(sales_frame['full_address'])\n",
    "\n",
    "# Construct full address for parser:\n",
    "sales_frame['full_address'] = sales_frame['full_address'] + ', SAN-FRANCISCO, CA ' + sales_frame['zip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Normalize full address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse, concatenate, drop duplicate columns:\n",
    "df_out=pd.DataFrame(list(sales_frame.full_address.apply(lambda x: catch_norm_tag(x))), index=sales_frame.index)\n",
    "df_out.index = sales_frame.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>zip</th>\n",
       "      <th>no1</th>\n",
       "      <th>street_name</th>\n",
       "      <th>street_type</th>\n",
       "      <th>unit_number</th>\n",
       "      <th>street_suffix</th>\n",
       "      <th>address_number</th>\n",
       "      <th>full_address</th>\n",
       "      <th>e_tag</th>\n",
       "      <th>e_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 NORTHWOOD DRIVE</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>NORTHWOOD</td>\n",
       "      <td>DR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>northwood drive</td>\n",
       "      <td>1</td>\n",
       "      <td>1 NORTHWOOD DRIVE, SAN-FRANCISCO, CA 94112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2909 Jennings Street</td>\n",
       "      <td>94124</td>\n",
       "      <td>2909</td>\n",
       "      <td>JENNINGS</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jennings street</td>\n",
       "      <td>2909</td>\n",
       "      <td>2909 JENNINGS STREET, SAN-FRANCISCO, CA 94124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>631 Ofarrell 503</td>\n",
       "      <td>94109</td>\n",
       "      <td>631</td>\n",
       "      <td>OFARRELL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ofarrell</td>\n",
       "      <td>631</td>\n",
       "      <td>631 OFARRELL, UNIT 503, SAN-FRANCISCO, CA 94109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>250 Minerva</td>\n",
       "      <td>94112</td>\n",
       "      <td>250</td>\n",
       "      <td>MINERVA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>minerva</td>\n",
       "      <td>250</td>\n",
       "      <td>250 MINERVA, SAN-FRANCISCO, CA 94112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4021 Folsom</td>\n",
       "      <td>94110</td>\n",
       "      <td>4021</td>\n",
       "      <td>FOLSOM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>folsom</td>\n",
       "      <td>4021</td>\n",
       "      <td>4021 FOLSOM, SAN-FRANCISCO, CA 94110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                address    zip   no1 street_name street_type unit_number  \\\n",
       "0     1 NORTHWOOD DRIVE  94112     1   NORTHWOOD          DR         NaN   \n",
       "1  2909 Jennings Street  94124  2909    JENNINGS          ST         NaN   \n",
       "2      631 Ofarrell 503  94109   631    OFARRELL         NaN         NaN   \n",
       "3           250 Minerva  94112   250     MINERVA         NaN         NaN   \n",
       "4           4021 Folsom  94110  4021      FOLSOM         NaN         NaN   \n",
       "\n",
       "     street_suffix address_number  \\\n",
       "0  northwood drive              1   \n",
       "1  jennings street           2909   \n",
       "2        ofarrell             631   \n",
       "3         minerva             250   \n",
       "4          folsom            4021   \n",
       "\n",
       "                                      full_address e_tag e_norm  \n",
       "0       1 NORTHWOOD DRIVE, SAN-FRANCISCO, CA 94112   NaN    NaN  \n",
       "1    2909 JENNINGS STREET, SAN-FRANCISCO, CA 94124   NaN    NaN  \n",
       "2  631 OFARRELL, UNIT 503, SAN-FRANCISCO, CA 94109   NaN    NaN  \n",
       "3             250 MINERVA, SAN-FRANCISCO, CA 94112   NaN    NaN  \n",
       "4             4021 FOLSOM, SAN-FRANCISCO, CA 94110   NaN    NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = df_out.e_norm.isna() | df_out.e_tag.isna()\n",
    "\n",
    "# Keep exceptions:\n",
    "sales_frame[['e_tag', 'e_norm']]= df_out[['e_tag', 'e_norm']]\n",
    "\n",
    "# Replace with normalized columns:\n",
    "for c in ['address_number','street_name','street_type','unit_number']:\n",
    "    sales_frame.loc[m,c] = df_out.loc[m,c]\n",
    "\n",
    "sales_frame.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Match streets with FuzzyWuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FuzzyWuzzy application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of streets:\n",
    "sales_frame['street_name_type'] = (sales_frame.street_name.fillna('') +\\\n",
    "                                    ' '+sales_frame.street_type.fillna('')).str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▋                                                                           | 170/3591 [00:01<00:47, 72.72it/s]WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3591/3591 [02:45<00:00, 21.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set of streets without suffix:\n",
    "street_name_set = set(addy_frame['street_name'].dropna().unique())\n",
    "                      \n",
    "sales_frame['addy_street_name'], sales_frame['addy_street_name_score'] =\\\n",
    "fuzzy_series(sales_frame['street_name_type'], street_name_set, thresh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▋                                                                           | 170/3591 [00:13<04:16, 13.36it/s]WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3591/3591 [03:07<00:00, 19.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Set of streets with suffix:\n",
    "street_name_type_set = set((addy_frame.street_name.fillna('')+' '+addy_frame.street_type.fillna('')).unique())\n",
    "\n",
    "sales_frame['addy_street_name_type'], sales_frame['addy_street_name_type_score'] =\\\n",
    "fuzzy_series(sales_frame['street_name_type'], street_name_type_set, thresh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9823315924581747"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = (sales_frame['addy_street_name_score']>=91)|(sales_frame['addy_street_name_type_score']>=91)\n",
    "sum(m)/sales_frame.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026113127378950165"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sales_frame.street_name_type.str.strip() == '')/sales_frame.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Match street and numbers:\n",
    "#### 3.4.1 Replace canonical street_name_type\n",
    "Depending on FuzzyWuzzy score, replace original street name with canonical street name with or without street type.\n",
    "Note: we cannot autoatically add street_type at this point if it is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_frame['number_street_type'] = sales_frame['street_name_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m91 = (sales_frame['addy_street_name_score']>=91)|(sales_frame['addy_street_name_type_score']>=91)\n",
    "msfx = sales_frame['addy_street_name_type_score'] >= sales_frame['addy_street_name_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_frame.loc[~m91,'number_street_type'] = '#####'\n",
    "sales_frame.loc[m91 & ~msfx,'number_street_type'] = sales_frame.loc[~msfx,'addy_street_name']\n",
    "sales_frame.loc[m91 & msfx,'number_street_type'] = sales_frame.loc[msfx,'addy_street_name_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_frame['number_street_type'] = sales_frame['address_number']+' '+ sales_frame['number_street_type']#+' '+sales_frame['unit'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Find mathcing addresses\n",
    "After street_type is adjusted add street_number and look for mathcing addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addy without suffix:\n",
    "addy_frame['number_street'] = addy_frame.address_number.astype(str)+\\\n",
    "' '+addy_frame.street_name.str.strip() \n",
    "addy_frame['number_street_type'] = addy_frame.address_number.astype(str)+\\\n",
    "' '+addy_frame.street_name.str.strip() +' '+addy_frame.street_type.str.strip() \n",
    "\n",
    "# Set of streets with suffix:\n",
    "addy_number_street_set = set(addy_frame['number_street'].dropna().unique())\n",
    "addy_number_street_type_set = set(addy_frame['number_street_type'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████████████████▍                                                    | 8987/28296 [03:14<06:46, 47.51it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5e40c2adc4d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mjdx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddy_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maddy_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'number_street'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msales_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'street_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddy_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mjdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'street_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0msales_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'number_street_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddy_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mjdx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'number_street_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1027\u001b[0m                 \u001b[1;31m# scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m                     \u001b[0msetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36msetter\u001b[1;34m(item, v)\u001b[0m\n\u001b[0;32m    959\u001b[0m                     \u001b[1;31m# set the item, possibly having a dtype change\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 961\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    962\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5809\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5810\u001b[0m         \"\"\"\n\u001b[1;32m-> 5811\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5812\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"copy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Add type to streets that match without street_type:\n",
    "m = sales_frame['number_street_type'].isin(addy_number_street_set)\n",
    "ser = sales_frame['number_street_type'][m]\n",
    " \n",
    "for idx in tqdm(ser.index):\n",
    "    jdx = addy_frame[addy_frame['number_street'].isin([ser.loc[idx]])].index[0]\n",
    "    sales_frame.loc[idx, 'street_type'] = addy_frame.loc[jdx, 'street_type']\n",
    "    sales_frame.loc[idx, 'number_street_type'] = addy_frame.loc[jdx, 'number_street_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_frame['found'] = sales_frame['number_street_type'].isin(addy_number_street_type_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_frame['found'].sum()/sales_frame.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addy_frame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addy_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_out = pd.merge(sales_frame.loc[sales_frame.found, ['address','number_street_type']],\n",
    "         addy_frame[['number_street_type','long','lat']],\n",
    "         how='inner', \n",
    "         on =['number_street_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sales data:\n",
    "sales_path = r'C:\\SFSU\\Spring 2020\\Project\\Data\\salesframe.csv' # use your path\n",
    "sales_frame = pd.read_csv(sales_path, header=0, index_col=False, \n",
    "                         dtype={'Zip Code':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.3 Match and geotag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_out = pd.merge(sales_out, sales_frame,\n",
    "                      how='left', \n",
    "                      left_on = ['address'],\n",
    "                      right_on =['Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_out.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_path = r'C:\\SFSU\\Spring 2020\\Project\\Data\\salesframe_tagged.csv'\n",
    "sales_out.to_csv(sales_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_path = r'C:\\SFSU\\Spring 2020\\Project\\Data\\salesframe_tagged.csv'\n",
    "sales_out = pd.read_csv(sales_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_path = r'C:\\SFSU\\Spring 2020\\Project\\Data\\assessor\\Historic_Secured_Property_Tax_Rolls_Processed.csv'\n",
    "assess_out = pd.read_csv(assess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['Number of Bedrooms','Property Area in Square Feet','Lot Area']:\n",
    "    assess_out[c] = pd.to_numeric(assess_out[c], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ['Beds','Property Area in Square Feet','Lot Area']:\n",
    "    sales_out[c] = pd.to_numeric(sales_out[c], errors='coerce', downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(sales_out, assess_out,\n",
    "                      how='inner', \n",
    "                      left_on = ['number_street_type','Beds'],\n",
    "                      right_on =['number_street_type','Number of Bedrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_out.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
